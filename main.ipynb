{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import time\n",
    "import pyrealsense2 as rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=YOLO(\"best.pt\")\n",
    "filepath = \"modelrestnet.h5\"\n",
    "model2 = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth and yolo\n",
    "def depth():\n",
    "    # Configure depth and color streams\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "    config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "    # Start streaming\n",
    "    pipeline.start(config)\n",
    "    depth_ar=[]\n",
    "    try:\n",
    "        while True:\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            depth = frames.get_depth_frame()\n",
    "            if not color_frame:\n",
    "                continue\n",
    "\n",
    "            img = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            results = model1(img)\n",
    "            for result in results:\n",
    "                cv2.imshow('RealSense', result.plot())\n",
    "                cv2.waitKey(100)\n",
    "                cord = result.boxes.xyxy\n",
    "                if(len(cord)!=0):\n",
    "                    x1=cord[0][0]\n",
    "                    x2=cord[0][2]\n",
    "                    y1=cord[0][1]\n",
    "                    y2=cord[0][3]\n",
    "                    (x,y) = (x2 + x1)/2, (y2+y1)/2\n",
    "                    zDepth = depth.get_distance(int(x),int(y))\n",
    "                    print(zDepth)\n",
    "                    depth_ar.append(zDepth)\n",
    "                    if(zDepth<= 2):\n",
    "                        break\n",
    "                    #segmentation\n",
    "                    # mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "                    # cv2.rectangle(mask, (x1, y1), (x2, y2), (255), thickness=-1)\n",
    "                    # segmented_image = cv2.bitwise_and(img, img, mask=mask)\n",
    "                    # cv2.imshow('Segmented Image', segmented_image)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        # Stop streaming\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "    return zDepth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrow direction detection\n",
    "def detect():\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "    # Start streaming\n",
    "    pipeline.start(config)\n",
    "    def array2dir(array):\n",
    "        none_prob = 0.4\n",
    "        print(\"Model output array:\", array[0][0],array[0][1],array[0][2],array[0][3])  # Debugging line to see the output array\n",
    "        down_prob, left_prob, rightprob, up_prob = array[0][:4]  # Adjust to take the first three values\n",
    "        right_prob = rightprob\n",
    "        if left_prob > right_prob and left_prob > up_prob and left_prob>down_prob and left_prob>none_prob:\n",
    "            print(\"left\")\n",
    "        elif right_prob > left_prob and right_prob > up_prob and right_prob>down_prob and right_prob>none_prob:\n",
    "            print(\"right\")\n",
    "        elif up_prob > left_prob and up_prob > right_prob and up_prob>down_prob and up_prob>none_prob:\n",
    "            print(\"up\")\n",
    "        elif down_prob > left_prob and down_prob > right_prob and down_prob>up_prob and down_prob>none_prob:\n",
    "            print(\"down\")\n",
    "        else:\n",
    "            print(\"none\")\n",
    "    \n",
    "    #detection \n",
    "    start_time = time.time()\n",
    "    duration = 15  # Run for 5 seconds\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            if not color_frame:\n",
    "                continue\n",
    "\n",
    "            img = np.asanyarray(color_frame.get_data())\n",
    "            cv2.imshow('RealSense', img)\n",
    "            img = cv2.resize(img, (224, 224))  # Resize image\n",
    "            img = np.asarray(img)  # Convert image to numpy array\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "            output = model2.predict(img)  # Perform prediction using the loaded model\n",
    "            array2dir(output)  # Call function to interpret the prediction\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            # Stop after the specified duration\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > duration:\n",
    "                print(f\"Stopping after {duration} seconds.\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Stop streaming\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x800 (no detections), 232.0ms\n",
      "Speed: 0.0ms preprocess, 232.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 210.4ms\n",
      "Speed: 10.0ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 204.8ms\n",
      "Speed: 0.0ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 216.7ms\n",
      "Speed: 15.6ms preprocess, 216.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 198.7ms\n",
      "Speed: 15.8ms preprocess, 198.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.9ms\n",
      "Speed: 10.2ms preprocess, 208.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 226.2ms\n",
      "Speed: 0.0ms preprocess, 226.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 213.1ms\n",
      "Speed: 0.0ms preprocess, 213.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.0ms\n",
      "Speed: 5.6ms preprocess, 200.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 204.8ms\n",
      "Speed: 0.0ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 210.9ms\n",
      "Speed: 0.0ms preprocess, 210.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 230.7ms\n",
      "Speed: 0.0ms preprocess, 230.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 205.0ms\n",
      "Speed: 0.0ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 194.5ms\n",
      "Speed: 10.0ms preprocess, 194.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 196.4ms\n",
      "Speed: 17.6ms preprocess, 196.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 202.0ms\n",
      "Speed: 8.4ms preprocess, 202.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 205.0ms\n",
      "Speed: 10.1ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 196.0ms\n",
      "Speed: 0.0ms preprocess, 196.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 190.7ms\n",
      "Speed: 8.1ms preprocess, 190.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 213.7ms\n",
      "Speed: 8.7ms preprocess, 213.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 207.8ms\n",
      "Speed: 13.5ms preprocess, 207.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 206.8ms\n",
      "Speed: 15.7ms preprocess, 206.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 206.7ms\n",
      "Speed: 8.2ms preprocess, 206.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 199.5ms\n",
      "Speed: 8.7ms preprocess, 199.5ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 206.7ms\n",
      "Speed: 8.0ms preprocess, 206.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 199.6ms\n",
      "Speed: 8.2ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 207.8ms\n",
      "Speed: 7.6ms preprocess, 207.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.5ms\n",
      "Speed: 6.9ms preprocess, 208.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 199.3ms\n",
      "Speed: 8.4ms preprocess, 199.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 220.0ms\n",
      "Speed: 8.6ms preprocess, 220.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.5440000295639038\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 210.4ms\n",
      "Speed: 6.5ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4880000352859497\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 199.6ms\n",
      "Speed: 0.0ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4480000138282776\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 216.8ms\n",
      "Speed: 7.5ms preprocess, 216.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4710000157356262\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 199.8ms\n",
      "Speed: 0.0ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.47600001096725464\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 216.2ms\n",
      "Speed: 8.2ms preprocess, 216.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.47200003266334534\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 193.3ms\n",
      "Speed: 0.0ms preprocess, 193.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.47700002789497375\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 204.8ms\n",
      "Speed: 10.4ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46800002455711365\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 205.3ms\n",
      "Speed: 10.4ms preprocess, 205.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46700000762939453\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 197.2ms\n",
      "Speed: 0.0ms preprocess, 197.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46700000762939453\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 175.5ms\n",
      "Speed: 0.0ms preprocess, 175.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46700000762939453\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 216.1ms\n",
      "Speed: 7.9ms preprocess, 216.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4650000333786011\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 207.0ms\n",
      "Speed: 0.0ms preprocess, 207.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46800002455711365\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 199.3ms\n",
      "Speed: 7.2ms preprocess, 199.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46700000762939453\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 199.6ms\n",
      "Speed: 7.8ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4710000157356262\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 199.9ms\n",
      "Speed: 0.0ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4690000116825104\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 208.1ms\n",
      "Speed: 8.0ms preprocess, 208.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4700000286102295\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 203.9ms\n",
      "Speed: 8.1ms preprocess, 203.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4690000116825104\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 198.5ms\n",
      "Speed: 8.9ms preprocess, 198.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46700000762939453\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 194.4ms\n",
      "Speed: 10.1ms preprocess, 194.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4660000205039978\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 216.4ms\n",
      "Speed: 4.4ms preprocess, 216.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.46400001645088196\n",
      "\n",
      "0: 480x800 (no detections), 209.5ms\n",
      "Speed: 5.3ms preprocess, 209.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.6ms\n",
      "Speed: 5.6ms preprocess, 208.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.0ms\n",
      "Speed: 6.6ms preprocess, 200.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 216.9ms\n",
      "Speed: 7.2ms preprocess, 216.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.9ms\n",
      "Speed: 6.9ms preprocess, 200.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 203.1ms\n",
      "Speed: 15.4ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.6ms\n",
      "Speed: 12.9ms preprocess, 200.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 216.4ms\n",
      "Speed: 7.7ms preprocess, 216.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 214.7ms\n",
      "Speed: 8.1ms preprocess, 214.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 209.8ms\n",
      "Speed: 0.0ms preprocess, 209.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 197.7ms\n",
      "Speed: 10.7ms preprocess, 197.7ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 220.1ms\n",
      "Speed: 11.5ms preprocess, 220.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 223.5ms\n",
      "Speed: 7.5ms preprocess, 223.5ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.8ms\n",
      "Speed: 0.0ms preprocess, 208.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.2ms\n",
      "Speed: 0.0ms preprocess, 208.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 214.2ms\n",
      "Speed: 0.0ms preprocess, 214.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 199.9ms\n",
      "Speed: 2.2ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 203.8ms\n",
      "Speed: 10.1ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 202.0ms\n",
      "Speed: 0.0ms preprocess, 202.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 209.5ms\n",
      "Speed: 10.5ms preprocess, 209.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 210.6ms\n",
      "Speed: 11.4ms preprocess, 210.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.2ms\n",
      "Speed: 3.6ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 201.9ms\n",
      "Speed: 2.2ms preprocess, 201.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 208.4ms\n",
      "Speed: 4.3ms preprocess, 208.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.2ms\n",
      "Speed: 10.2ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 210.3ms\n",
      "Speed: 5.9ms preprocess, 210.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 181.3ms\n",
      "Speed: 0.0ms preprocess, 181.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 194.5ms\n",
      "Speed: 10.5ms preprocess, 194.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 212.9ms\n",
      "Speed: 12.4ms preprocess, 212.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 212.7ms\n",
      "Speed: 0.0ms preprocess, 212.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 219.5ms\n",
      "Speed: 0.0ms preprocess, 219.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 213.8ms\n",
      "Speed: 6.5ms preprocess, 213.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 222.8ms\n",
      "Speed: 0.0ms preprocess, 222.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.7420000433921814\n",
      "\n",
      "0: 480x800 (no detections), 225.3ms\n",
      "Speed: 0.0ms preprocess, 225.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 194.0ms\n",
      "Speed: 4.4ms preprocess, 194.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 204.7ms\n",
      "Speed: 0.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 197.0ms\n",
      "Speed: 15.6ms preprocess, 197.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 200.8ms\n",
      "Speed: 0.0ms preprocess, 200.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 217.6ms\n",
      "Speed: 10.6ms preprocess, 217.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 210.4ms\n",
      "Speed: 10.0ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 194.9ms\n",
      "Speed: 0.0ms preprocess, 194.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4230000078678131\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 214.6ms\n",
      "Speed: 10.9ms preprocess, 214.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.42000001668930054\n",
      "\n",
      "0: 480x800 (no detections), 225.4ms\n",
      "Speed: 6.9ms preprocess, 225.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 191.1ms\n",
      "Speed: 4.5ms preprocess, 191.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.41700002551078796\n",
      "\n",
      "0: 480x800 (no detections), 219.2ms\n",
      "Speed: 0.0ms preprocess, 219.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 212.4ms\n",
      "Speed: 6.1ms preprocess, 212.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.4150000214576721\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 206.5ms\n",
      "Speed: 4.6ms preprocess, 206.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.41700002551078796\n",
      "\n",
      "0: 480x800 2 arrows-rLOps, 203.4ms\n",
      "Speed: 0.0ms preprocess, 203.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.39900001883506775\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 193.1ms\n",
      "Speed: 6.2ms preprocess, 193.1ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.3850000202655792\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 200.5ms\n",
      "Speed: 0.0ms preprocess, 200.5ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.38700002431869507\n",
      "\n",
      "0: 480x800 1 arrows-rLOp, 205.8ms\n",
      "Speed: 0.0ms preprocess, 205.8ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "0.39100003242492676\n",
      "\n",
      "0: 480x800 (no detections), 200.5ms\n",
      "Speed: 3.0ms preprocess, 200.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 215.3ms\n",
      "Speed: 8.5ms preprocess, 215.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 195.9ms\n",
      "Speed: 4.5ms preprocess, 195.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 (no detections), 205.8ms\n",
      "Speed: 5.5ms preprocess, 205.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m depth1 \u001b[38;5;241m=\u001b[39m \u001b[43mdepth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(depth1\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      3\u001b[0m     direction \u001b[38;5;241m=\u001b[39m detect()\n",
      "Cell \u001b[1;32mIn[58], line 21\u001b[0m, in \u001b[0;36mdepth\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     19\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(color_frame\u001b[38;5;241m.\u001b[39mget_data())\n\u001b[1;32m---> 21\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     23\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRealSense\u001b[39m\u001b[38;5;124m'\u001b[39m, result\u001b[38;5;241m.\u001b[39mplot())\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\engine\\model.py:173\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    146\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\engine\\model.py:563\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:456\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 456\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:239\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 239\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:239\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 239\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:349\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depth1 = depth()\n",
    "if(depth1<=2):\n",
    "    direction = detect()\n",
    "if(direction == \"left\"):\n",
    "    out=-1\n",
    "elif(direction == \"right\"):\n",
    "    out=1\n",
    "else:\n",
    "    out=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
