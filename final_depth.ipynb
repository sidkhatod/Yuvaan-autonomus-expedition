{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "model=YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realtime Start\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 308.5ms\n",
      "Speed: 5.5ms preprocess, 308.5ms inference, 12.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 (no detections), 281.1ms\n",
      "Speed: 0.0ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 255.8ms\n",
      "Speed: 14.6ms preprocess, 255.8ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 265.2ms\n",
      "Speed: 0.0ms preprocess, 265.2ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 242.6ms\n",
      "Speed: 5.9ms preprocess, 242.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 249.4ms\n",
      "Speed: 10.0ms preprocess, 249.4ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 252.4ms\n",
      "Speed: 15.5ms preprocess, 252.4ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 240.5ms\n",
      "Speed: 0.0ms preprocess, 240.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.281000018119812\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 251.0ms\n",
      "Speed: 15.7ms preprocess, 251.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2670000195503235\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 241.0ms\n",
      "Speed: 0.0ms preprocess, 241.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.26500001549720764\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 248.4ms\n",
      "Speed: 16.2ms preprocess, 248.4ms inference, 7.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2639999985694885\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 247.4ms\n",
      "Speed: 13.2ms preprocess, 247.4ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2590000033378601\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 248.7ms\n",
      "Speed: 8.3ms preprocess, 248.7ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2600000202655792\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 243.7ms\n",
      "Speed: 2.2ms preprocess, 243.7ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2580000162124634\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 242.2ms\n",
      "Speed: 4.5ms preprocess, 242.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2639999985694885\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 244.2ms\n",
      "Speed: 15.8ms preprocess, 244.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.5170000195503235\n",
      "\n",
      "0: 608x800 2 arrows-rLOps, 240.8ms\n",
      "Speed: 10.1ms preprocess, 240.8ms inference, 5.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.26900002360343933\n",
      "\n",
      "0: 608x800 (no detections), 242.5ms\n",
      "Speed: 0.0ms preprocess, 242.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 249.5ms\n",
      "Speed: 4.0ms preprocess, 249.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 282.7ms\n",
      "Speed: 8.4ms preprocess, 282.7ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 274.0ms\n",
      "Speed: 4.7ms preprocess, 274.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 249.7ms\n",
      "Speed: 5.4ms preprocess, 249.7ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.0\n",
      "\n",
      "0: 608x800 1 arrows-rLOp, 247.1ms\n",
      "Speed: 5.6ms preprocess, 247.1ms inference, 3.8ms postprocess per image at shape (1, 3, 608, 800)\n",
      "0.2580000162124634\n",
      "Stopping after 15 seconds.\n",
      "[0.0, 0.0, 0.0, 0.0, 0.281000018119812, 0.2670000195503235, 0.26500001549720764, 0.2639999985694885, 0.2590000033378601, 0.2600000202655792, 0.2580000162124634, 0.2639999985694885, 0.5170000195503235, 0.26900002360343933, 0.0, 0.0, 0.0, 0.0, 0.2580000162124634]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import pyrealsense2 as rs\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "print(\"Realtime Start\")\n",
    "start_time = time.time()\n",
    "duration = 15  # Run for 5 seconds\n",
    "depth_ar=[]\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth = frames.get_depth_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        img = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        results = model(img)\n",
    "        for result in results:\n",
    "            #print(result.boxes)\n",
    "            # result.show()\n",
    "            cv2.imshow('RealSense', result.plot())\n",
    "            cv2.waitKey(100)  # Small delay to allow the window to be rendered\n",
    "            #cv2.destroyAllWindows()\n",
    "            #print(result.boxes.xyxy)\n",
    "            cord = result.boxes.xyxy\n",
    "            if(len(cord)!=0):\n",
    "                x1=cord[0][0]\n",
    "                x2=cord[0][2]\n",
    "                y1=cord[0][1]\n",
    "                y2=cord[0][3]\n",
    "                (x,y) = (x2 + x1)/2, (y2+y1)/2\n",
    "                zDepth = depth.get_distance(int(x),int(y))\n",
    "                print(zDepth)\n",
    "                depth_ar.append(zDepth)\n",
    "                #segmentation\n",
    "                # mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "                # cv2.rectangle(mask, (x1, y1), (x2, y2), (255), thickness=-1)\n",
    "                # segmented_image = cv2.bitwise_and(img, img, mask=mask)\n",
    "                # cv2.imshow('Segmented Image', segmented_image)\n",
    "            else:\n",
    "                 continue\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Stop after the specified duration\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > duration:\n",
    "            print(f\"Stopping after {duration} seconds.\")\n",
    "            print(depth_ar)\n",
    "            break\n",
    "finally:\n",
    "        # Stop streaming\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
